{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Unit 1 â€“ Feature Engineering & Data Pipelines\n","\n","Use this notebook to practice turning messy event data into a clean, reusable feature pipeline."]},{"cell_type":"markdown","metadata":{},"source":["## 1. Setup and data loading\n","\n","Run the cell below to import libraries and load the sample dataset from `../data/unit1_events.csv`."]},{"cell_type":"code","metadata":{},"source":["import pandas as pd\n","from pathlib import Path\n","\n","data_path = Path('..') / 'data' / 'unit1_events.csv'\n","df = pd.read_csv(data_path, parse_dates=['event_timestamp'])\n","\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["## 2. Data understanding\n","\n","Explore column types, missing values and basic distributions. Add your own analysis cells below."]},{"cell_type":"code","metadata":{},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{},"source":["## 3. Baseline manual cleaning and simple model\n","\n","Use ad-hoc Pandas code to clean the data and fit a simple baseline model (e.g. churn prediction or spend regression)." ]},{"cell_type":"markdown","metadata":{},"source":["## 4. Proper feature pipeline with ColumnTransformer + Pipeline\n","\n","Refactor your cleaning steps into a scikit-learn `ColumnTransformer` and `Pipeline`, then fit/evaluate a model."]},{"cell_type":"markdown","metadata":{},"source":["## 5. Leakage example (what not to do)\n","\n","Demonstrate a pipeline that incorrectly uses information from validation/test data, and compare metrics."]},{"cell_type":"markdown","metadata":{},"source":["## 6. Save the fitted pipeline\n","\n","Once you are happy with your pipeline and model, save it with `joblib` under `../artifacts/u1_feature_pipeline.joblib`."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12"}},"nbformat":4,"nbformat_minor":5}
