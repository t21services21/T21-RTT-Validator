# ğŸ§ª TEST THE LEARNING SYSTEM

## Quick Test Guide

### **Step 1: Test Core Infrastructure**

Run this in Python console or terminal:

```bash
cd C:\Users\User\CascadeProjects\T21-RTT-Validator
python learning_system_core.py
```

**Expected Output:**
```
T21 Learning System initialized successfully!
Database: t21_learning_system.db
Added test example: ID 1
Example Library Stats:
{
  "letter_interpreter": {
    "categories": {
      "referral": {
        "count": 1,
        "avg_quality": 1.0,
        "total_usage": 0
      }
    },
    "total_examples": 1
  }
}
```

âœ… If you see this â†’ Core system working!

---

### **Step 2: Test Anonymization**

```bash
python data_anonymizer.py
```

**Expected Output:**
```
ORIGINAL LETTER:
Dear Dr Smith,
Re: John Doe, DOB 15/03/1975, NHS Number: 123 456 7890
...

ANONYMIZED LETTER:
Dear Dr Smith,
Re: [NAME], DOB [DATE], NHS Number: XXX XXX XXXX
...

VALIDATION:
Is Safe: True
Risk Level: LOW
Warnings: []
```

âœ… If patient data is removed â†’ Anonymization working!

---

### **Step 3: Test RAG System**

```bash
python letter_interpreter_rag.py
```

**Expected Output:**
```
T21 Letter Interpreter RAG System

Added test examples

Retrieved 2 contextual examples:

Example 1:
  Input: GP referral for chest pain investigation...
  Output: 18/10/2025 T21 - REF REC'D 01/10/2025 FOR CHEST PAIN...
  Specialty: Cardiology

Learning Statistics:
{
  "example_library": {
    "total_examples": 2,
    "categories": {
      "referral": {
        "count": 1
      },
      "discharge": {
        "count": 1
      }
    }
  }
}

Improvement Suggestions:
[MEDIUM] Need more examples for treatment letters
  Action: Save validated treatment letters to improve AI accuracy
```

âœ… If examples are retrieved â†’ RAG working!

---

### **Step 4: Test In Streamlit App**

1. **Start the app:**
```bash
streamlit run app.py
```

2. **Navigate to:** Pages â†’ Clinic Letter Interpreter

3. **Upload a test letter** (or paste text)

4. **Click:** "ğŸ“ Interpret & Teach Me"

5. **Scroll to bottom** after interpretation

6. **Look for:** "ğŸ§  Help The System Learn!" section

7. **Click:** "âœ… Perfect - Save as Example"

8. **Check:** "ğŸ“Š Learning System Stats" expander

**Expected:**
- âœ… Balloons animation
- âœ… "Thank you! Example saved to learning library"
- âœ… Stats show: "Total validated examples: 1"

---

### **Step 5: Test Learning Improvement**

1. **Upload ANOTHER similar letter** (same type/specialty)

2. **The system should:**
   - Retrieve your saved example
   - Use it as context for AI
   - Give better interpretation

3. **Check the prompt enhancement** (in code):
   - AI now sees: "Learn from these validated examples..."
   - Your example is shown as context

---

## ğŸ¯ What To Test For

### **Feedback Collection:**
- âœ… "Perfect" button saves example
- âœ… "Wrong" button shows correction form
- âœ… Correction form accepts input
- âœ… Stats update after saving

### **Anonymization:**
- âœ… NHS numbers removed
- âœ… Patient names removed
- âœ… Postcodes removed
- âœ… Clinical info preserved

### **RAG Retrieval:**
- âœ… Similar examples retrieved
- âœ… Specialty filtering works
- âœ… Category filtering works
- âœ… Usage count increments

### **Learning Over Time:**
- âœ… More examples = better accuracy
- âœ… Examples specific to your trust
- âœ… Specialty expertise develops

---

## ğŸ“Š Check Database Directly

**View the database:**
```bash
# Install DB Browser for SQLite (free tool)
# Open: t21_learning_system.db

# Or use command line:
sqlite3 t21_learning_system.db

# Run queries:
SELECT COUNT(*) FROM example_library;
SELECT * FROM example_library LIMIT 5;
SELECT module, COUNT(*) FROM feedback GROUP BY module;
```

**Expected Tables:**
- example_library
- feedback
- patterns
- analytics
- insights

---

## ğŸ› Common Issues & Fixes

### **Issue: "Learning system not available" warning**
**Fix:** 
```bash
# Check files exist:
ls learning_system_core.py
ls data_anonymizer.py
ls letter_interpreter_rag.py

# Restart Streamlit
```

### **Issue: Database error**
**Fix:**
```bash
# Delete and recreate
rm t21_learning_system.db
python learning_system_core.py
```

### **Issue: Import errors**
**Fix:**
```bash
# Install required packages
pip install openai PyPDF2 python-docx
```

### **Issue: Feedback buttons don't work**
**Fix:**
- Ensure you clicked "Interpret" first
- Check browser console for errors
- Try refreshing page

---

## âœ… Success Checklist

- [ ] Core system initializes
- [ ] Database created
- [ ] Test examples added
- [ ] Anonymization removes patient data
- [ ] RAG retrieves similar examples
- [ ] Feedback UI appears in app
- [ ] "Perfect" button saves example
- [ ] Stats show saved examples
- [ ] Correction form works
- [ ] Database tables populated

---

## ğŸ“ˆ Track Improvements

### **Week 1:**
- Examples saved: _______
- Accuracy improvement: _______
- Feedback participation: _______

### **Month 1:**
- Examples saved: _______
- Accuracy improvement: _______
- Time saved per letter: _______

### **Month 3:**
- Examples saved: _______
- Accuracy improvement: _______
- Coverage gaps filled: _______

---

## ğŸ‰ Ready For Production?

Before rolling out to all validators:

1. âœ… Test with 10-20 real letters
2. âœ… Verify anonymization is working
3. âœ… Confirm examples are useful
4. âœ… Check database performance
5. âœ… Brief validators on feedback process
6. âœ… Set up monitoring/analytics

---

**The learning system is LIVE and ready to make your platform smarter!**

Every validation you do now teaches the AI. 
Every correction you make improves future accuracy.
Every example you save helps the next validator.

**Welcome to AI that learns from YOUR expertise!** ğŸš€
